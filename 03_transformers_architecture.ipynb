{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137042fe",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/badge/python-3.9-blue)\n",
    "![Status: Pending Migration](https://img.shields.io/badge/status-pending%20migration-orange)\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ“– Transformers Architecture\n",
    "\n",
    "- [ğŸ§  Why Transformers?](#why-transformers)\n",
    "- [ğŸ”¡ Embeddings and Tokens](#embeddings-and-tokens)\n",
    "    - [ğŸ§± Tokenization Basics](#tokenization-basics)\n",
    "    - [ğŸ”¢ Word, Subword, and Sentence Embeddings](#embedding-types)\n",
    "    - [ğŸ“ Positional Encoding](#positional-encoding)\n",
    "- [ğŸŒ€ Attention Mechanism](#attention-mechanism)\n",
    "    - [ğŸ‘€ What is Attention?](#what-is-attention)\n",
    "    - [ğŸ“ Scaled Dot-Product Attention](#scaled-dot-product-attention)\n",
    "    - [ğŸ›ï¸ Multi-Head Attention](#multi-head-attention)\n",
    "- [ğŸ—ï¸ Transformer Building Blocks](#transformer-building-blocks)\n",
    "    - [ğŸ§± Layer Norm, Residuals, and Feedforward Layers](#transformer-components)\n",
    "    - [ğŸ” Encoder vs Decoder Structure](#encoder-vs-decoder)\n",
    "- [ğŸ“¦ End-to-End Transformer Flow](#transformer-end-to-end)\n",
    "    - [ğŸ“ˆ Training Objective (Next Token, MLM, etc.)](#training-objectives)\n",
    "    - [ğŸ“¤ Inference: Autoregression and Decoding](#transformer-inference)\n",
    "- [ğŸ” Why This Matters for Our Use Cases](#why-this-matters)\n",
    "    - [ğŸ’¬ Chatbot â†’ Decoder-only Transformers](#chatbot-transformers)\n",
    "    - [ğŸ“ Summarization â†’ Encoder-Decoder Transformers](#summarization-transformers)\n",
    "    - [ğŸ“Š Sentiment Analysis â†’ Encoder-only Models](#sentiment-transformers)\n",
    "- [ğŸ”š Closing Notes](#closing-notes)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5a8ce",
   "metadata": {},
   "source": [
    "<a id=\"why-transformers\"></a>\n",
    "# ğŸ§  Why Transformers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e5101",
   "metadata": {},
   "source": [
    "<a id=\"embeddings-and-tokens\"></a>\n",
    "# ğŸ”¡ Embeddings and Tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82138b6",
   "metadata": {},
   "source": [
    "<a id=\"tokenization-basics\"></a>\n",
    "#### ğŸ§± Tokenization Basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8d3d3",
   "metadata": {},
   "source": [
    "<a id=\"embedding-types\"></a>\n",
    "#### ğŸ”¢ Word, Subword, and Sentence Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a24680",
   "metadata": {},
   "source": [
    "<a id=\"positional-encoding\"></a>\n",
    "#### ğŸ“ Positional Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a09f1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6196a1d",
   "metadata": {},
   "source": [
    "<a id=\"attention-mechanism\"></a>\n",
    "# ğŸŒ€ Attention Mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2e028",
   "metadata": {},
   "source": [
    "<a id=\"what-is-attention\"></a>\n",
    "#### ğŸ‘€ What is Attention?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136ef9d",
   "metadata": {},
   "source": [
    "<a id=\"scaled-dot-product-attention\"></a>\n",
    "#### ğŸ“ Scaled Dot-Product Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db73e57",
   "metadata": {},
   "source": [
    "<a id=\"multi-head-attention\"></a>\n",
    "#### ğŸ›ï¸ Multi-Head Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ddfc9",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61bd73",
   "metadata": {},
   "source": [
    "<a id=\"transformer-building-blocks\"></a>\n",
    "# ğŸ—ï¸ Transformer Building Blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4c9d9",
   "metadata": {},
   "source": [
    "<a id=\"transformer-components\"></a>\n",
    "#### ğŸ§± Layer Norm, Residuals, and Feedforward Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f8fca",
   "metadata": {},
   "source": [
    "<a id=\"encoder-vs-decoder\"></a>\n",
    "#### ğŸ” Encoder vs Decoder Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4b1a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93e788a6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a3583",
   "metadata": {},
   "source": [
    "<a id=\"transformer-end-to-end\"></a>\n",
    "# ğŸ“¦ End-to-End Transformer Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc36c7",
   "metadata": {},
   "source": [
    "<a id=\"training-objectives\"></a>\n",
    "#### ğŸ“ˆ Training Objective (Next Token, MLM, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059e141",
   "metadata": {},
   "source": [
    "<a id=\"transformer-inference\"></a>\n",
    "#### ğŸ“¤ Inference: Autoregression and Decoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5e011",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a9d9f",
   "metadata": {},
   "source": [
    "<a id=\"why-this-matters\"></a>\n",
    "# ğŸ” Why This Matters for Our Use Cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07aa8f8",
   "metadata": {},
   "source": [
    "<a id=\"chatbot-transformers\"></a>\n",
    "#### ğŸ’¬ Chatbot â†’ Decoder-only Transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b879d1",
   "metadata": {},
   "source": [
    "<a id=\"summarization-transformers\"></a>\n",
    "#### ğŸ“ Summarization â†’ Encoder-Decoder Transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d4982",
   "metadata": {},
   "source": [
    "<a id=\"sentiment-transformers\"></a>\n",
    "#### ğŸ“Š Sentiment Analysis â†’ Encoder-only Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599c26a",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de78ba1",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ”š Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe813feb",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
