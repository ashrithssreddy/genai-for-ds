{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137042fe",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/badge/python-3.9-blue)\n",
    "![Status: Pending Migration](https://img.shields.io/badge/status-pending%20migration-orange)\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ“– Transformers: The Architecture That Changed NLP\n",
    "\n",
    "- [ğŸ§  Why Transformers?](#why-transformers)\n",
    "  - [ğŸ”„ Limits of RNNs and CNNs for Sequential Data](#limits-of-rnns-cnns)\n",
    "  - [ğŸ”— Need for Long-Range Dependencies](#long-range-dependencies)\n",
    "  - [â±ï¸ Parallelism and Efficiency](#parallelism-efficiency)\n",
    "- [ğŸ—ï¸ Core Building Blocks](#core-building-blocks)\n",
    "  - [ğŸ“¦ Embeddings](#embeddings)\n",
    "  - [ğŸ¯ Positional Encoding](#positional-encoding)\n",
    "  - [ğŸ§® Self-Attention Mechanism](#self-attention)\n",
    "  - [ğŸ§  Multi-head Attention](#multihead-attention)\n",
    "  - [ğŸ§± Feedforward Layers](#feedforward-layers)\n",
    "  - [ğŸ” Layer Norm, Skip Connections](#layer-norm)\n",
    "- [ğŸ”¬ The Transformer Block](#transformer-block)\n",
    "  - [ğŸ” Encoder Block (Structure + Flow)](#encoder-block)\n",
    "  - [ğŸ” Decoder Block (Structure + Flow)](#decoder-block)\n",
    "  - [ğŸ”„ Masking in Attention](#masking)\n",
    "  - [ğŸ“¶ Stack of N Layers](#stack-of-layers)\n",
    "- [ğŸ”¢ Attention Mechanism in Depth](#attention-in-depth)\n",
    "  - [ğŸ§  Attention as Weighted Lookup](#attention-weighted-lookup)\n",
    "  - [ğŸ“ Query, Key, Value Vectors](#qkv-vectors)\n",
    "  - [ğŸ“Š Dot-Product Attention Calculation](#dot-product-attention)\n",
    "  - [âš™ï¸ Softmax + Scaling](#softmax-scaling)\n",
    "- [ğŸ§° Training a Transformer Model](#training-transformer)\n",
    "  - [ğŸ“Š Example: Sequence Classification or Translation](#sequence-task-example)\n",
    "  - [ğŸ’¡ Tokenization (WordPiece/BPE) Basics](#tokenization)\n",
    "  - [ğŸ§® Input-Output Pipeline](#input-output-pipeline)\n",
    "- [ğŸ“š Transformers Beyond Text](#beyond-text)\n",
    "  - [ğŸ§  Use in Vision (ViT)](#transformers-vision)\n",
    "  - [ğŸ§ª Time Series and Tabular Data](#transformers-time-series)\n",
    "  - [ğŸ§¬ Multimodal Transformers](#multimodal-transformers)\n",
    "- [ğŸ§­ From Transformers to LLMs](#to-llms)\n",
    "  - [ğŸŒ Evolution: Transformer â†’ GPT/BERT â†’ LLMs](#evolution)\n",
    "  - [ğŸ“ˆ Scaling Laws (Depth, Width, Data)](#scaling-laws)\n",
    "  - [ğŸ” Pretraining Objectives: Causal vs. Masked](#pretraining-objectives)\n",
    "- [ğŸ”š Closing Notes](#closing-notes)\n",
    "  - [âš ï¸ Conceptual Pitfalls](#pitfalls)\n",
    "  - [ğŸ” Visual Explainers and Demos to Explore](#visual-explainers)\n",
    "  - [ğŸš€ Next Up: Large Language Models (04)](#next-llms)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a44c608",
   "metadata": {},
   "source": [
    "<a id=\"why-transformers\"></a>\n",
    "# ğŸ§  Why Transformers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97bdb92",
   "metadata": {},
   "source": [
    "<a id=\"limits-of-rnns-cnns\"></a>\n",
    "#### ğŸ”„ Limits of RNNs and CNNs for Sequential Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9944ad7",
   "metadata": {},
   "source": [
    "<a id=\"long-range-dependencies\"></a>\n",
    "#### ğŸ”— Need for Long-Range Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df012b9",
   "metadata": {},
   "source": [
    "<a id=\"parallelism-efficiency\"></a>\n",
    "#### â±ï¸ Parallelism and Efficiency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd8851",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72666e3",
   "metadata": {},
   "source": [
    "<a id=\"core-building-blocks\"></a>\n",
    "# ğŸ—ï¸ Core Building Blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13df38",
   "metadata": {},
   "source": [
    "<a id=\"embeddings\"></a>\n",
    "#### ğŸ“¦ Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718593a",
   "metadata": {},
   "source": [
    "<a id=\"positional-encoding\"></a>\n",
    "#### ğŸ¯ Positional Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d521e",
   "metadata": {},
   "source": [
    "<a id=\"self-attention\"></a>\n",
    "#### ğŸ§® Self-Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05be96",
   "metadata": {},
   "source": [
    "<a id=\"multihead-attention\"></a>\n",
    "#### ğŸ§  Multi-head Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb9645",
   "metadata": {},
   "source": [
    "<a id=\"feedforward-layers\"></a>\n",
    "#### ğŸ§± Feedforward Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b1263",
   "metadata": {},
   "source": [
    "<a id=\"layer-norm\"></a>\n",
    "#### ğŸ” Layer Norm, Skip Connections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7b4d4",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9878e",
   "metadata": {},
   "source": [
    "<a id=\"transformer-block\"></a>\n",
    "# ğŸ”¬ The Transformer Block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382dcaa",
   "metadata": {},
   "source": [
    "<a id=\"encoder-block\"></a>\n",
    "#### ğŸ” Encoder Block (Structure + Flow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f01e1",
   "metadata": {},
   "source": [
    "<a id=\"decoder-block\"></a>\n",
    "#### ğŸ” Decoder Block (Structure + Flow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7bb318",
   "metadata": {},
   "source": [
    "<a id=\"masking\"></a>\n",
    "#### ğŸ”„ Masking in Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece8b18",
   "metadata": {},
   "source": [
    "<a id=\"stack-of-layers\"></a>\n",
    "#### ğŸ“¶ Stack of N Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c38f68",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36224f",
   "metadata": {},
   "source": [
    "<a id=\"attention-in-depth\"></a>\n",
    "# ğŸ”¢ Attention Mechanism in Depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac0b56",
   "metadata": {},
   "source": [
    "<a id=\"attention-weighted-lookup\"></a>\n",
    "#### ğŸ§  Attention as Weighted Lookup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44ba84",
   "metadata": {},
   "source": [
    "<a id=\"qkv-vectors\"></a>\n",
    "#### ğŸ“ Query, Key, Value Vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b95f82",
   "metadata": {},
   "source": [
    "<a id=\"dot-product-attention\"></a>\n",
    "#### ğŸ“Š Dot-Product Attention Calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444ab5f",
   "metadata": {},
   "source": [
    "<a id=\"softmax-scaling\"></a>\n",
    "#### âš™ï¸ Softmax + Scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d45ec",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8339ad0",
   "metadata": {},
   "source": [
    "<a id=\"training-transformer\"></a>\n",
    "# ğŸ§° Training a Transformer Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ae73d",
   "metadata": {},
   "source": [
    "<a id=\"sequence-task-example\"></a>\n",
    "#### ğŸ“Š Example: Sequence Classification or Translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a0ab2",
   "metadata": {},
   "source": [
    "<a id=\"tokenization\"></a>\n",
    "#### ğŸ’¡ Tokenization (WordPiece/BPE) Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269315a",
   "metadata": {},
   "source": [
    "<a id=\"input-output-pipeline\"></a>\n",
    "#### ğŸ§® Input-Output Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893a802",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29287f00",
   "metadata": {},
   "source": [
    "<a id=\"beyond-text\"></a>\n",
    "# ğŸ“š Transformers Beyond Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd587708",
   "metadata": {},
   "source": [
    "<a id=\"transformers-vision\"></a>\n",
    "#### ğŸ§  Use in Vision (ViT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10366f94",
   "metadata": {},
   "source": [
    "<a id=\"transformers-time-series\"></a>\n",
    "#### ğŸ§ª Time Series and Tabular Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f63ac2",
   "metadata": {},
   "source": [
    "<a id=\"multimodal-transformers\"></a>\n",
    "#### ğŸ§¬ Multimodal Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a804535",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a3c9c",
   "metadata": {},
   "source": [
    "<a id=\"to-llms\"></a>\n",
    "# ğŸ§­ From Transformers to LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87c2d8",
   "metadata": {},
   "source": [
    "<a id=\"evolution\"></a>\n",
    "#### ğŸŒ Evolution: Transformer â†’ GPT/BERT â†’ LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743d7e5",
   "metadata": {},
   "source": [
    "<a id=\"scaling-laws\"></a>\n",
    "#### ğŸ“ˆ Scaling Laws (Depth, Width, Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae48e31",
   "metadata": {},
   "source": [
    "<a id=\"pretraining-objectives\"></a>\n",
    "#### ğŸ” Pretraining Objectives: Causal vs. Masked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b00966a",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e372ce5",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ”š Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee653916",
   "metadata": {},
   "source": [
    "<a id=\"pitfalls\"></a>\n",
    "#### âš ï¸ Conceptual Pitfalls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c347b",
   "metadata": {},
   "source": [
    "<a id=\"visual-explainers\"></a>\n",
    "#### ğŸ” Visual Explainers and Demos to Explore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805851a",
   "metadata": {},
   "source": [
    "<a id=\"next-llms\"></a>\n",
    "#### ğŸš€ Next Up: Large Language Models (04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ced4d",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
