{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9222fa",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/badge/python-3.9-blue)\n",
    "![Status: Pending Migration](https://img.shields.io/badge/status-pending%20migration-orange)\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ“– Large Language Models (LLMs)\n",
    "\n",
    "- [ğŸ§  What are LLMs?](#what-are-llms)\n",
    "  - [ğŸ” Definition and Intuition](#definition)\n",
    "  - [ğŸ—ï¸ LLM vs. Standard Transformer](#llm-vs-transformer)\n",
    "  - [ğŸ“ Typical Sizes (Parameters, Layers, Data)](#model-sizes)\n",
    "- [ğŸ‹ï¸ Pretraining LLMs](#pretraining-llms)\n",
    "  - [ğŸ“– Causal Language Modeling (CLM)](#clm)\n",
    "  - [ğŸ§© Masked Language Modeling (MLM)](#mlm)\n",
    "  - [ğŸ” Next Sentence Prediction and Others](#nsp-etc)\n",
    "  - [ğŸ§  Self-supervised Learning Explained](#self-supervised)\n",
    "- [ğŸ” Fine-tuning Strategies](#fine-tuning)\n",
    "  - [ğŸ¯ Task-specific Fine-tuning](#task-specific)\n",
    "  - [ğŸ§ª Instruction Tuning](#instruction-tuning)\n",
    "  - [ğŸ’¬ RLHF (Reinforcement Learning with Human Feedback)](#rlhf)\n",
    "  - [ğŸ§° Parameter-Efficient Tuning (LoRA, Adapters)](#parameter-efficient)\n",
    "- [ğŸ“Š Evaluation of LLMs](#evaluation)\n",
    "  - [âœ… Standard Benchmarks (GLUE, HELM, MMLU)](#benchmarks)\n",
    "  - [ğŸ§  Measuring Hallucination, Bias, Toxicity](#hallucination-bias)\n",
    "  - [âš–ï¸ Tradeoffs: Size vs. Accuracy vs. Inference Cost](#tradeoffs)\n",
    "- [ğŸ§° LLM Capabilities and Limitations](#capabilities-limitations)\n",
    "  - [ğŸ§  Emergent Behaviors at Scale](#emergent-behaviors)\n",
    "  - [ğŸ› ï¸ In-Context Learning](#in-context)\n",
    "  - [ğŸ§¨ Hallucinations and Failures](#hallucinations)\n",
    "  - [ğŸ“‰ Prompt Sensitivity](#prompt-sensitivity)\n",
    "- [ğŸš€ Use Cases and Applications](#use-cases)\n",
    "  - [ğŸ’¬ Chatbots and Assistants](#chatbots)\n",
    "  - [ğŸ“„ Text Summarization](#summarization)\n",
    "  - [ğŸ” Search + RAG (Retrieval-Augmented Generation)](#rag)\n",
    "  - [ğŸ§  Reasoning, Coding, Math, and Beyond](#reasoning-coding)\n",
    "- [ğŸ” Risks and Ethical Concerns](#risks)\n",
    "  - [ğŸ” Model Misuse and Jailbreaks](#misuse)\n",
    "  - [ğŸ”¬ Biases and Stereotyping](#biases)\n",
    "  - [ğŸ”’ Privacy, Copyright, and Data Leakage](#privacy)\n",
    "  - [âš–ï¸ Responsible Deployment](#responsible-deployment)\n",
    "- [ğŸ”§ Building with LLMs Today](#building-today)\n",
    "  - [ğŸ¤– Open vs. Closed Models](#open-vs-closed)\n",
    "  - [ğŸ§° APIs (OpenAI, Anthropic, Cohere)](#api-access)\n",
    "  - [âš™ï¸ Open-source (LLaMA, Mistral, Falcon)](#open-source-models)\n",
    "  - [ğŸ§  Model Selection Tips](#model-selection)\n",
    "- [ğŸ”š Closing Notes](#closing-notes)\n",
    "  - [ğŸ§­ Summary and Key Takeaways](#summary)\n",
    "  - [ğŸš€ Next Up: Prompt Engineering (05)](#next-up)\n",
    "  - [ğŸ§  What to Practice](#what-to-practice)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35375ca9",
   "metadata": {},
   "source": [
    "<a id=\"what-are-llms\"></a>\n",
    "# ğŸ§  What are LLMs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e6e16",
   "metadata": {},
   "source": [
    "<a id=\"definition\"></a>\n",
    "#### ğŸ” Definition and Intuition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1baea58",
   "metadata": {},
   "source": [
    "<a id=\"llm-vs-transformer\"></a>\n",
    "#### ğŸ—ï¸ LLM vs. Standard Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc8058",
   "metadata": {},
   "source": [
    "<a id=\"model-sizes\"></a>\n",
    "#### ğŸ“ Typical Sizes (Parameters, Layers, Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0808249",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad035e",
   "metadata": {},
   "source": [
    "<a id=\"pretraining-llms\"></a>\n",
    "# ğŸ‹ï¸ Pretraining LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c8eac",
   "metadata": {},
   "source": [
    "<a id=\"clm\"></a>\n",
    "#### ğŸ“– Causal Language Modeling (CLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12662c49",
   "metadata": {},
   "source": [
    "<a id=\"mlm\"></a>\n",
    "#### ğŸ§© Masked Language Modeling (MLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a41f30",
   "metadata": {},
   "source": [
    "<a id=\"nsp-etc\"></a>\n",
    "#### ğŸ” Next Sentence Prediction and Others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc01054",
   "metadata": {},
   "source": [
    "<a id=\"self-supervised\"></a>\n",
    "#### ğŸ§  Self-supervised Learning Explained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4ba21",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ca53f",
   "metadata": {},
   "source": [
    "<a id=\"fine-tuning\"></a>\n",
    "# ğŸ” Fine-tuning Strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f459efe",
   "metadata": {},
   "source": [
    "<a id=\"task-specific\"></a>\n",
    "#### ğŸ¯ Task-specific Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8834a3",
   "metadata": {},
   "source": [
    "<a id=\"instruction-tuning\"></a>\n",
    "#### ğŸ§ª Instruction Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7364c33",
   "metadata": {},
   "source": [
    "<a id=\"rlhf\"></a>\n",
    "#### ğŸ’¬ RLHF (Reinforcement Learning with Human Feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48ff34",
   "metadata": {},
   "source": [
    "<a id=\"parameter-efficient\"></a>\n",
    "#### ğŸ§° Parameter-Efficient Tuning (LoRA, Adapters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02128858",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fbd7b",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "# ğŸ“Š Evaluation of LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51481b1f",
   "metadata": {},
   "source": [
    "<a id=\"benchmarks\"></a>\n",
    "#### âœ… Standard Benchmarks (GLUE, HELM, MMLU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61760845",
   "metadata": {},
   "source": [
    "<a id=\"hallucination-bias\"></a>\n",
    "#### ğŸ§  Measuring Hallucination, Bias, Toxicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb3256",
   "metadata": {},
   "source": [
    "<a id=\"tradeoffs\"></a>\n",
    "#### âš–ï¸ Tradeoffs: Size vs. Accuracy vs. Inference Cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dfe916",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f1243",
   "metadata": {},
   "source": [
    "<a id=\"capabilities-limitations\"></a>\n",
    "# ğŸ§° LLM Capabilities and Limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5f9da",
   "metadata": {},
   "source": [
    "<a id=\"emergent-behaviors\"></a>\n",
    "#### ğŸ§  Emergent Behaviors at Scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2953e6",
   "metadata": {},
   "source": [
    "<a id=\"in-context\"></a>\n",
    "#### ğŸ› ï¸ In-Context Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc84149",
   "metadata": {},
   "source": [
    "<a id=\"hallucinations\"></a>\n",
    "#### ğŸ§¨ Hallucinations and Failures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f8e67",
   "metadata": {},
   "source": [
    "<a id=\"prompt-sensitivity\"></a>\n",
    "#### ğŸ“‰ Prompt Sensitivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c373eb27",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f676b7",
   "metadata": {},
   "source": [
    "<a id=\"use-cases\"></a>\n",
    "# ğŸš€ Use Cases and Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b2fa2",
   "metadata": {},
   "source": [
    "<a id=\"chatbots\"></a>\n",
    "#### ğŸ’¬ Chatbots and Assistants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d96d0a",
   "metadata": {},
   "source": [
    "<a id=\"summarization\"></a>\n",
    "#### ğŸ“„ Text Summarization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be60b74",
   "metadata": {},
   "source": [
    "<a id=\"rag\"></a>\n",
    "#### ğŸ” Search + RAG (Retrieval-Augmented Generation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb19fe",
   "metadata": {},
   "source": [
    "<a id=\"reasoning-coding\"></a>\n",
    "#### ğŸ§  Reasoning, Coding, Math, and Beyond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62289330",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fb805",
   "metadata": {},
   "source": [
    "<a id=\"risks\"></a>\n",
    "# ğŸ” Risks and Ethical Concerns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e87c0",
   "metadata": {},
   "source": [
    "<a id=\"misuse\"></a>\n",
    "#### ğŸ” Model Misuse and Jailbreaks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7905701a",
   "metadata": {},
   "source": [
    "<a id=\"biases\"></a>\n",
    "#### ğŸ”¬ Biases and Stereotyping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62556dc7",
   "metadata": {},
   "source": [
    "<a id=\"privacy\"></a>\n",
    "#### ğŸ”’ Privacy, Copyright, and Data Leakage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c4fd14",
   "metadata": {},
   "source": [
    "<a id=\"responsible-deployment\"></a>\n",
    "#### âš–ï¸ Responsible Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c46b7",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd504773",
   "metadata": {},
   "source": [
    "<a id=\"building-today\"></a>\n",
    "# ğŸ”§ Building with LLMs Today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de24ae5",
   "metadata": {},
   "source": [
    "<a id=\"open-vs-closed\"></a>\n",
    "#### ğŸ¤– Open vs. Closed Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fa335",
   "metadata": {},
   "source": [
    "<a id=\"api-access\"></a>\n",
    "#### ğŸ§° APIs (OpenAI, Anthropic, Cohere)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e3af4",
   "metadata": {},
   "source": [
    "<a id=\"open-source-models\"></a>\n",
    "#### âš™ï¸ Open-source (LLaMA, Mistral, Falcon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0136177",
   "metadata": {},
   "source": [
    "<a id=\"model-selection\"></a>\n",
    "#### ğŸ§  Model Selection Tips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e336bf",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5f38fe",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ”š Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b7f8e",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "#### ğŸ§­ Summary and Key Takeaways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5abdcc",
   "metadata": {},
   "source": [
    "<a id=\"next-up\"></a>\n",
    "#### ğŸš€ Next Up: Prompt Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14a32a",
   "metadata": {},
   "source": [
    "<a id=\"what-to-practice\"></a>\n",
    "#### ğŸ§  What to Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f8f47",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9dfb15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
