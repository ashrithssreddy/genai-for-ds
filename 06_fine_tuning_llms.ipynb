{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8ee9dc",
   "metadata": {},
   "source": [
    "<a id=\"table-of-contents\"></a>\n",
    "# 📖 Fine-tuning LLMs\n",
    "\n",
    "- [🧠 Why Fine-tune a Language Model?](#why-fine-tune)\n",
    "  - [🔄 Prompting Limitations](#prompting-limitations)\n",
    "  - [🎯 Use Cases for Fine-tuning](#use-cases)\n",
    "  - [🧠 Behavioral vs. Task-Specific Tuning](#behavioral-vs-task)\n",
    "- [⚙️ Types of Fine-tuning](#types-of-finetuning)\n",
    "  - [🧰 Full Fine-tuning](#full-finetuning)\n",
    "  - [🧱 Adapter-based Tuning](#adapter-tuning)\n",
    "  - [🧪 LoRA (Low-Rank Adaptation)](#lora)\n",
    "  - [🎛️ Prefix/Prompt Tuning](#prefix-tuning)\n",
    "- [🛠️ Fine-tuning Pipeline Overview](#pipeline-overview)\n",
    "  - [📄 Data Collection and Formatting](#data-collection)\n",
    "  - [🧹 Preprocessing and Tokenization](#preprocessing)\n",
    "  - [🔧 Training Setup and Config](#training-setup)\n",
    "  - [📉 Evaluation and Checkpoints](#checkpoints)\n",
    "- [📦 Tools and Frameworks](#tools-frameworks)\n",
    "  - [🤗 Hugging Face Transformers + Datasets](#hf-transformers)\n",
    "  - [🧠 PEFT (Parameter-Efficient Fine-Tuning)](#peft)\n",
    "  - [🧪 OpenLLM, Axolotl, LoRA Libraries](#openllm-lora)\n",
    "- [📊 Case Studies / Example Walkthroughs](#case-studies)\n",
    "  - [📄 Fine-tuning for Text Classification](#text-classification)\n",
    "  - [💬 Fine-tuning for Q&A](#qa)\n",
    "  - [🤖 Fine-tuning for Chatbots](#chatbots)\n",
    "- [⚖️ Tradeoffs and Considerations](#tradeoffs)\n",
    "  - [💰 Compute and Cost Constraints](#costs)\n",
    "  - [🧠 Catastrophic Forgetting](#forgetting)\n",
    "  - [🔄 Overfitting to Instruction Style](#overfitting)\n",
    "- [🧪 Evaluation Best Practices](#evaluation)\n",
    "  - [🧠 Task-specific Metrics](#task-metrics)\n",
    "  - [🔍 Manual Review of Generations](#manual-review)\n",
    "  - [📊 Comparing Baseline vs. Fine-tuned](#baseline-vs-finetuned)\n",
    "- [🔚 Closing Notes](#closing-notes)\n",
    "  - [🧭 Summary and When to Fine-tune](#summary)\n",
    "  - [🚀 Next Up: Hugging Face Workflows (07)](#next)\n",
    "  - [🧠 What to Try on Your Own](#try-yourself)\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d39654",
   "metadata": {},
   "source": [
    "<a id=\"why-fine-tune\"></a>\n",
    "# 🧠 Why Fine-tune a Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6d81",
   "metadata": {},
   "source": [
    "<a id=\"prompting-limitations\"></a>\n",
    "#### 🔄 Prompting Limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a9b83",
   "metadata": {},
   "source": [
    "<a id=\"use-cases\"></a>\n",
    "#### 🎯 Use Cases for Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47a333",
   "metadata": {},
   "source": [
    "<a id=\"behavioral-vs-task\"></a>\n",
    "#### 🧠 Behavioral vs. Task-Specific Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19381be8",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7424e",
   "metadata": {},
   "source": [
    "<a id=\"types-of-finetuning\"></a>\n",
    "# ⚙️ Types of Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3037c5",
   "metadata": {},
   "source": [
    "<a id=\"full-finetuning\"></a>\n",
    "#### 🧰 Full Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3251cb6",
   "metadata": {},
   "source": [
    "<a id=\"adapter-tuning\"></a>\n",
    "#### 🧱 Adapter-based Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2a2e2",
   "metadata": {},
   "source": [
    "<a id=\"lora\"></a>\n",
    "#### 🧪 LoRA (Low-Rank Adaptation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d789e5",
   "metadata": {},
   "source": [
    "<a id=\"prefix-tuning\"></a>\n",
    "#### 🎛️ Prefix/Prompt Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2b0db",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827291c1",
   "metadata": {},
   "source": [
    "<a id=\"pipeline-overview\"></a>\n",
    "# 🛠️ Fine-tuning Pipeline Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144718b",
   "metadata": {},
   "source": [
    "<a id=\"data-collection\"></a>\n",
    "#### 📄 Data Collection and Formatting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bd519",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "#### 🧹 Preprocessing and Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c8e6d",
   "metadata": {},
   "source": [
    "<a id=\"training-setup\"></a>\n",
    "#### 🔧 Training Setup and Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff1096",
   "metadata": {},
   "source": [
    "<a id=\"checkpoints\"></a>\n",
    "#### 📉 Evaluation and Checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc08643",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d26ce",
   "metadata": {},
   "source": [
    "<a id=\"tools-frameworks\"></a>\n",
    "# 📦 Tools and Frameworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36c199",
   "metadata": {},
   "source": [
    "<a id=\"hf-transformers\"></a>\n",
    "#### 🤗 Hugging Face Transformers + Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc90ae3",
   "metadata": {},
   "source": [
    "<a id=\"peft\"></a>\n",
    "#### 🧠 PEFT (Parameter-Efficient Fine-Tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1c49c",
   "metadata": {},
   "source": [
    "<a id=\"openllm-lora\"></a>\n",
    "#### 🧪 OpenLLM, Axolotl, LoRA Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3468abd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21192d4b",
   "metadata": {},
   "source": [
    "<a id=\"case-studies\"></a>\n",
    "# 📊 Case Studies / Example Walkthroughs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfb737",
   "metadata": {},
   "source": [
    "<a id=\"text-classification\"></a>\n",
    "#### 📄 Fine-tuning for Text Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b9ec8",
   "metadata": {},
   "source": [
    "<a id=\"qa\"></a>\n",
    "#### 💬 Fine-tuning for Q&A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3d413",
   "metadata": {},
   "source": [
    "<a id=\"chatbots\"></a>\n",
    "#### 🤖 Fine-tuning for Chatbots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d705d",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ea7a1",
   "metadata": {},
   "source": [
    "<a id=\"tradeoffs\"></a>\n",
    "# ⚖️ Tradeoffs and Considerations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6f0d0",
   "metadata": {},
   "source": [
    "<a id=\"costs\"></a>\n",
    "#### 💰 Compute and Cost Constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba47635",
   "metadata": {},
   "source": [
    "<a id=\"forgetting\"></a>\n",
    "#### 🧠 Catastrophic Forgetting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33845d83",
   "metadata": {},
   "source": [
    "<a id=\"overfitting\"></a>\n",
    "#### 🔄 Overfitting to Instruction Style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c145c5",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa313f38",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "# 🧪 Evaluation Best Practices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408649e4",
   "metadata": {},
   "source": [
    "<a id=\"task-metrics\"></a>\n",
    "#### 🧠 Task-specific Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bda0a1",
   "metadata": {},
   "source": [
    "<a id=\"manual-review\"></a>\n",
    "#### 🔍 Manual Review of Generations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da28c3c",
   "metadata": {},
   "source": [
    "<a id=\"baseline-vs-finetuned\"></a>\n",
    "#### 📊 Comparing Baseline vs. Fine-tuned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3473a54",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c79037",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# 🔚 Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b892e1",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "#### 🧭 Summary and When to Fine-tune\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef1341",
   "metadata": {},
   "source": [
    "<a id=\"next\"></a>\n",
    "#### 🚀 Next Up: Hugging Face Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a9a3f",
   "metadata": {},
   "source": [
    "<a id=\"try-yourself\"></a>\n",
    "#### 🧠 What to Try on Your Own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13231ab",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
