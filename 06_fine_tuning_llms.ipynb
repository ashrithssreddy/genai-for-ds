{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8ee9dc",
   "metadata": {},
   "source": [
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ“– Fine-tuning LLMs\n",
    "\n",
    "- [ğŸ§  Why Fine-tune a Language Model?](#why-fine-tune)\n",
    "  - [ğŸ”„ Prompting Limitations](#prompting-limitations)\n",
    "  - [ğŸ¯ Use Cases for Fine-tuning](#use-cases)\n",
    "  - [ğŸ§  Behavioral vs. Task-Specific Tuning](#behavioral-vs-task)\n",
    "- [âš™ï¸ Types of Fine-tuning](#types-of-finetuning)\n",
    "  - [ğŸ§° Full Fine-tuning](#full-finetuning)\n",
    "  - [ğŸ§± Adapter-based Tuning](#adapter-tuning)\n",
    "  - [ğŸ§ª LoRA (Low-Rank Adaptation)](#lora)\n",
    "  - [ğŸ›ï¸ Prefix/Prompt Tuning](#prefix-tuning)\n",
    "- [ğŸ› ï¸ Fine-tuning Pipeline Overview](#pipeline-overview)\n",
    "  - [ğŸ“„ Data Collection and Formatting](#data-collection)\n",
    "  - [ğŸ§¹ Preprocessing and Tokenization](#preprocessing)\n",
    "  - [ğŸ”§ Training Setup and Config](#training-setup)\n",
    "  - [ğŸ“‰ Evaluation and Checkpoints](#checkpoints)\n",
    "- [ğŸ“¦ Tools and Frameworks](#tools-frameworks)\n",
    "  - [ğŸ¤— Hugging Face Transformers + Datasets](#hf-transformers)\n",
    "  - [ğŸ§  PEFT (Parameter-Efficient Fine-Tuning)](#peft)\n",
    "  - [ğŸ§ª OpenLLM, Axolotl, LoRA Libraries](#openllm-lora)\n",
    "- [ğŸ“Š Case Studies / Example Walkthroughs](#case-studies)\n",
    "  - [ğŸ“„ Fine-tuning for Text Classification](#text-classification)\n",
    "  - [ğŸ’¬ Fine-tuning for Q&A](#qa)\n",
    "  - [ğŸ¤– Fine-tuning for Chatbots](#chatbots)\n",
    "- [âš–ï¸ Tradeoffs and Considerations](#tradeoffs)\n",
    "  - [ğŸ’° Compute and Cost Constraints](#costs)\n",
    "  - [ğŸ§  Catastrophic Forgetting](#forgetting)\n",
    "  - [ğŸ”„ Overfitting to Instruction Style](#overfitting)\n",
    "- [ğŸ§ª Evaluation Best Practices](#evaluation)\n",
    "  - [ğŸ§  Task-specific Metrics](#task-metrics)\n",
    "  - [ğŸ” Manual Review of Generations](#manual-review)\n",
    "  - [ğŸ“Š Comparing Baseline vs. Fine-tuned](#baseline-vs-finetuned)\n",
    "- [ğŸ”š Closing Notes](#closing-notes)\n",
    "  - [ğŸ§­ Summary and When to Fine-tune](#summary)\n",
    "  - [ğŸš€ Next Up: Hugging Face Workflows (07)](#next)\n",
    "  - [ğŸ§  What to Try on Your Own](#try-yourself)\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d39654",
   "metadata": {},
   "source": [
    "<a id=\"why-fine-tune\"></a>\n",
    "# ğŸ§  Why Fine-tune a Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6d81",
   "metadata": {},
   "source": [
    "<a id=\"prompting-limitations\"></a>\n",
    "#### ğŸ”„ Prompting Limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a9b83",
   "metadata": {},
   "source": [
    "<a id=\"use-cases\"></a>\n",
    "#### ğŸ¯ Use Cases for Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47a333",
   "metadata": {},
   "source": [
    "<a id=\"behavioral-vs-task\"></a>\n",
    "#### ğŸ§  Behavioral vs. Task-Specific Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19381be8",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7424e",
   "metadata": {},
   "source": [
    "<a id=\"types-of-finetuning\"></a>\n",
    "# âš™ï¸ Types of Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3037c5",
   "metadata": {},
   "source": [
    "<a id=\"full-finetuning\"></a>\n",
    "#### ğŸ§° Full Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3251cb6",
   "metadata": {},
   "source": [
    "<a id=\"adapter-tuning\"></a>\n",
    "#### ğŸ§± Adapter-based Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2a2e2",
   "metadata": {},
   "source": [
    "<a id=\"lora\"></a>\n",
    "#### ğŸ§ª LoRA (Low-Rank Adaptation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d789e5",
   "metadata": {},
   "source": [
    "<a id=\"prefix-tuning\"></a>\n",
    "#### ğŸ›ï¸ Prefix/Prompt Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2b0db",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827291c1",
   "metadata": {},
   "source": [
    "<a id=\"pipeline-overview\"></a>\n",
    "# ğŸ› ï¸ Fine-tuning Pipeline Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144718b",
   "metadata": {},
   "source": [
    "<a id=\"data-collection\"></a>\n",
    "#### ğŸ“„ Data Collection and Formatting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bd519",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "#### ğŸ§¹ Preprocessing and Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c8e6d",
   "metadata": {},
   "source": [
    "<a id=\"training-setup\"></a>\n",
    "#### ğŸ”§ Training Setup and Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff1096",
   "metadata": {},
   "source": [
    "<a id=\"checkpoints\"></a>\n",
    "#### ğŸ“‰ Evaluation and Checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc08643",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d26ce",
   "metadata": {},
   "source": [
    "<a id=\"tools-frameworks\"></a>\n",
    "# ğŸ“¦ Tools and Frameworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36c199",
   "metadata": {},
   "source": [
    "<a id=\"hf-transformers\"></a>\n",
    "#### ğŸ¤— Hugging Face Transformers + Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc90ae3",
   "metadata": {},
   "source": [
    "<a id=\"peft\"></a>\n",
    "#### ğŸ§  PEFT (Parameter-Efficient Fine-Tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1c49c",
   "metadata": {},
   "source": [
    "<a id=\"openllm-lora\"></a>\n",
    "#### ğŸ§ª OpenLLM, Axolotl, LoRA Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3468abd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21192d4b",
   "metadata": {},
   "source": [
    "<a id=\"case-studies\"></a>\n",
    "# ğŸ“Š Case Studies / Example Walkthroughs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfb737",
   "metadata": {},
   "source": [
    "<a id=\"text-classification\"></a>\n",
    "#### ğŸ“„ Fine-tuning for Text Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b9ec8",
   "metadata": {},
   "source": [
    "<a id=\"qa\"></a>\n",
    "#### ğŸ’¬ Fine-tuning for Q&A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3d413",
   "metadata": {},
   "source": [
    "<a id=\"chatbots\"></a>\n",
    "#### ğŸ¤– Fine-tuning for Chatbots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d705d",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ea7a1",
   "metadata": {},
   "source": [
    "<a id=\"tradeoffs\"></a>\n",
    "# âš–ï¸ Tradeoffs and Considerations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6f0d0",
   "metadata": {},
   "source": [
    "<a id=\"costs\"></a>\n",
    "#### ğŸ’° Compute and Cost Constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba47635",
   "metadata": {},
   "source": [
    "<a id=\"forgetting\"></a>\n",
    "#### ğŸ§  Catastrophic Forgetting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33845d83",
   "metadata": {},
   "source": [
    "<a id=\"overfitting\"></a>\n",
    "#### ğŸ”„ Overfitting to Instruction Style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c145c5",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa313f38",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "# ğŸ§ª Evaluation Best Practices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408649e4",
   "metadata": {},
   "source": [
    "<a id=\"task-metrics\"></a>\n",
    "#### ğŸ§  Task-specific Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bda0a1",
   "metadata": {},
   "source": [
    "<a id=\"manual-review\"></a>\n",
    "#### ğŸ” Manual Review of Generations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da28c3c",
   "metadata": {},
   "source": [
    "<a id=\"baseline-vs-finetuned\"></a>\n",
    "#### ğŸ“Š Comparing Baseline vs. Fine-tuned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3473a54",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c79037",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ”š Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b892e1",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "#### ğŸ§­ Summary and When to Fine-tune\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef1341",
   "metadata": {},
   "source": [
    "<a id=\"next\"></a>\n",
    "#### ğŸš€ Next Up: Hugging Face Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a9a3f",
   "metadata": {},
   "source": [
    "<a id=\"try-yourself\"></a>\n",
    "#### ğŸ§  What to Try on Your Own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13231ab",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
