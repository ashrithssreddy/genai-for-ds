{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bbd7d6",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/badge/python-3.9-blue)\n",
    "![Status: Pending Migration](https://img.shields.io/badge/status-pending%20migration-orange)\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ“– Hugging Face Workflows\n",
    "\n",
    "- [ğŸ§  What is Hugging Face?](#what-is-huggingface)\n",
    "  - [ğŸ¤— Overview of Ecosystem (Transformers, Datasets, Tokenizers, PEFT)](#ecosystem-overview)\n",
    "  - [ğŸ” Model Hub and Dataset Hub](#model-dataset-hub)\n",
    "  - [âš™ï¸ Pipelines vs. Manual Control](#pipelines-vs-manual)\n",
    "- [âš™ï¸ Core Workflow with Transformers](#core-workflow)\n",
    "  - [ğŸ§ª Load a Pretrained Model and Tokenizer](#load-model)\n",
    "  - [ğŸ’¬ Use Pipelines for Quick Tasks](#pipelines)\n",
    "  - [ğŸ“„ Custom Input Handling and Tokenization](#custom-tokenization)\n",
    "  - [ğŸ”§ Config, Tokenizer, and Model Outputs](#config-output)\n",
    "- [ğŸ§° Training and Fine-tuning with ğŸ¤—](#training-finetuning)\n",
    "  - [ğŸ§  Using Trainer API (End-to-End)](#trainer-api)\n",
    "  - [ğŸ“¦ Using Datasets Library](#datasets-lib)\n",
    "  - [ğŸ§® Custom Training Loops (if needed)](#custom-loops)\n",
    "  - [ğŸ§° PEFT / LoRA Integration](#peft-lora)\n",
    "- [ğŸ”¬ Evaluation and Inference](#evaluation)\n",
    "  - [ğŸ§ª Generate, Score, Classify](#generate-score)\n",
    "  - [ğŸ“Š Evaluate with Accuracy, BLEU, ROUGE](#eval-metrics)\n",
    "  - [ğŸ§  Save + Reload Model + Tokenizer](#save-reload)\n",
    "- [ğŸš€ Deployment Options](#deployment)\n",
    "  - [ğŸŒ Inference API](#inference-api)\n",
    "  - [ğŸ³ Docker + REST API (via FastAPI)](#docker-api)\n",
    "  - [ğŸ§  Accelerated Inference with ONNX or HF Optimum](#onnx-optimum)\n",
    "- [ğŸ› ï¸ Tips and Common Errors](#tips-errors)\n",
    "  - [âš ï¸ Tokenizer Shape Issues](#tokenizer-shape)\n",
    "  - [âš™ï¸ CUDA/Device Setup](#cuda-setup)\n",
    "  - [ğŸ” Debugging Model Outputs](#debug-output)\n",
    "- [ğŸ§ª Mini Projects or Use Cases](#mini-projects)\n",
    "  - [ğŸ’¬ Sentiment Classification](#sentiment)\n",
    "  - [ğŸ” Q&A or Search Reranking](#qa-search)\n",
    "  - [ğŸ§  Text Summarization](#summarization)\n",
    "- [ğŸ”š Closing Notes](#closing-notes)\n",
    "  - [ğŸ§  Summary and Key Commands](#summary)\n",
    "  - [ğŸ’¡ Next: GenAI Use Cases (08)](#next)\n",
    "  - [ğŸ§° Practice and Exploration Suggestions](#practice)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564ac4c",
   "metadata": {},
   "source": [
    "<a id=\"what-is-huggingface\"></a>\n",
    "# ğŸ§  What is Hugging Face?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b530e",
   "metadata": {},
   "source": [
    "<a id=\"ecosystem-overview\"></a>\n",
    "#### ğŸ¤— Overview of Ecosystem (Transformers, Datasets, Tokenizers, PEFT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c58c62",
   "metadata": {},
   "source": [
    "<a id=\"model-dataset-hub\"></a>\n",
    "#### ğŸ” Model Hub and Dataset Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab9c2e",
   "metadata": {},
   "source": [
    "<a id=\"pipelines-vs-manual\"></a>\n",
    "#### âš™ï¸ Pipelines vs. Manual Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b78ca",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b303b2a",
   "metadata": {},
   "source": [
    "<a id=\"core-workflow\"></a>\n",
    "# âš™ï¸ Core Workflow with Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6667253",
   "metadata": {},
   "source": [
    "<a id=\"load-model\"></a>\n",
    "#### ğŸ§ª Load a Pretrained Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053d326",
   "metadata": {},
   "source": [
    "<a id=\"pipelines\"></a>\n",
    "#### ğŸ’¬ Use Pipelines for Quick Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce35b49",
   "metadata": {},
   "source": [
    "<a id=\"custom-tokenization\"></a>\n",
    "#### ğŸ“„ Custom Input Handling and Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e53a8",
   "metadata": {},
   "source": [
    "<a id=\"config-output\"></a>\n",
    "#### ğŸ”§ Config, Tokenizer, and Model Outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c4c4ae",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704eaacd",
   "metadata": {},
   "source": [
    "<a id=\"training-finetuning\"></a>\n",
    "# ğŸ§° Training and Fine-tuning with ğŸ¤—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9813cc",
   "metadata": {},
   "source": [
    "<a id=\"trainer-api\"></a>\n",
    "#### ğŸ§  Using Trainer API (End-to-End)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9c0f3",
   "metadata": {},
   "source": [
    "<a id=\"datasets-lib\"></a>\n",
    "#### ğŸ“¦ Using Datasets Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee90af",
   "metadata": {},
   "source": [
    "<a id=\"custom-loops\"></a>\n",
    "#### ğŸ§® Custom Training Loops (if needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f201c",
   "metadata": {},
   "source": [
    "<a id=\"peft-lora\"></a>\n",
    "#### ğŸ§° PEFT / LoRA Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf993df",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc607b",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "# ğŸ”¬ Evaluation and Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137337f",
   "metadata": {},
   "source": [
    "<a id=\"generate-score\"></a>\n",
    "#### ğŸ§ª Generate, Score, Classify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d815e",
   "metadata": {},
   "source": [
    "<a id=\"eval-metrics\"></a>\n",
    "#### ğŸ“Š Evaluate with Accuracy, BLEU, ROUGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fbf12",
   "metadata": {},
   "source": [
    "<a id=\"save-reload\"></a>\n",
    "#### ğŸ§  Save + Reload Model + Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95050c5",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4aa46",
   "metadata": {},
   "source": [
    "<a id=\"deployment\"></a>\n",
    "# ğŸš€ Deployment Options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24853e6",
   "metadata": {},
   "source": [
    "<a id=\"inference-api\"></a>\n",
    "#### ğŸŒ Inference API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ef573",
   "metadata": {},
   "source": [
    "<a id=\"docker-api\"></a>\n",
    "#### ğŸ³ Docker + REST API (via FastAPI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d185f2",
   "metadata": {},
   "source": [
    "<a id=\"onnx-optimum\"></a>\n",
    "#### ğŸ§  Accelerated Inference with ONNX or HF Optimum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77710a0",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6634e47",
   "metadata": {},
   "source": [
    "<a id=\"tips-errors\"></a>\n",
    "# ğŸ› ï¸ Tips and Common Errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089e318",
   "metadata": {},
   "source": [
    "<a id=\"tokenizer-shape\"></a>\n",
    "#### âš ï¸ Tokenizer Shape Issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73b43d",
   "metadata": {},
   "source": [
    "<a id=\"cuda-setup\"></a>\n",
    "#### âš™ï¸ CUDA/Device Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b454a",
   "metadata": {},
   "source": [
    "<a id=\"debug-output\"></a>\n",
    "#### ğŸ” Debugging Model Outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa275040",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0d167",
   "metadata": {},
   "source": [
    "<a id=\"mini-projects\"></a>\n",
    "# ğŸ§ª Mini Projects or Use Cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd62822",
   "metadata": {},
   "source": [
    "<a id=\"sentiment\"></a>\n",
    "#### ğŸ’¬ Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c713fb",
   "metadata": {},
   "source": [
    "<a id=\"qa-search\"></a>\n",
    "#### ğŸ” Q&A or Search Reranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab1468",
   "metadata": {},
   "source": [
    "<a id=\"summarization\"></a>\n",
    "#### ğŸ§  Text Summarization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062835e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd0dda",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ”š Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b354f",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "#### ğŸ§  Summary and Key Commands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c7309",
   "metadata": {},
   "source": [
    "<a id=\"next\"></a>\n",
    "#### ğŸ’¡ Next: GenAI Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951225f",
   "metadata": {},
   "source": [
    "<a id=\"practice\"></a>\n",
    "#### ğŸ§° Practice and Exploration Suggestions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece3f7e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
