# GenAI Skills for Data Scientists

## ğŸ”¹ Core Concepts
- Basics of Large Language Models (LLMs)
- Tokens, embeddings, attention mechanism
- Prompt engineering: zero-shot, few-shot, chain-of-thought
- Sampling techniques: temperature, top-k, top-p
- Context window and token limits

## ğŸ”¹ Hands-On Skills

### ğŸ“¦ Model Usage
- Accessing models via OpenAI, HuggingFace APIs
- Running local models (LLaMA, Mistral, TinyLlama)
- Inference pipelines with `transformers`

### ğŸ§ª Experimentation
- Designing and testing prompts
- Evaluating output quality (manual, BLEU, ROUGE)
- Token cost and latency awareness (especially with APIs)

### ğŸ› ï¸ Tools & Libraries
- `transformers` (HuggingFace)
- `langchain`, `llama-index`
- `gradio`, `streamlit` for UI
- `wandb` for experiment tracking (optional)

## ğŸ”¹ Advanced Topics
- Retrieval-Augmented Generation (RAG)
- Tool use / agents (function calling via LLM)
- Finetuning models (LoRA, PEFT, QLoRA)
- Tokenization & embeddings (FAISS, OpenAI embeddings)
- Vector databases: Chroma, Pinecone, Weaviate

## ğŸ”¹ Data Science Crossovers
- Code generation for data tasks (Pandas, SQL, plotting)
- Summarization and classification of raw text data
- Applying LLMs to NLP tasks (NER, sentiment, etc.)
- Natural language querying over datasets
