{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137042fe",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/badge/python-3.9-blue)\n",
    "![Status: Pending Migration](https://img.shields.io/badge/status-pending%20migration-orange)\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# 📖 Transformers Architecture\n",
    "\n",
    "- [🧠 Why Transformers?](#why-transformers)\n",
    "- [🔡 Embeddings and Tokens](#embeddings-and-tokens)\n",
    "    - [🧱 Tokenization Basics](#tokenization-basics)\n",
    "    - [🔢 Word, Subword, and Sentence Embeddings](#embedding-types)\n",
    "    - [📐 Positional Encoding](#positional-encoding)\n",
    "- [🌀 Attention Mechanism](#attention-mechanism)\n",
    "    - [👀 What is Attention?](#what-is-attention)\n",
    "    - [📏 Scaled Dot-Product Attention](#scaled-dot-product-attention)\n",
    "    - [🎛️ Multi-Head Attention](#multi-head-attention)\n",
    "- [🏗️ Transformer Building Blocks](#transformer-building-blocks)\n",
    "    - [🧱 Layer Norm, Residuals, and Feedforward Layers](#transformer-components)\n",
    "    - [🔁 Encoder vs Decoder Structure](#encoder-vs-decoder)\n",
    "- [📦 End-to-End Transformer Flow](#transformer-end-to-end)\n",
    "    - [📈 Training Objective (Next Token, MLM, etc.)](#training-objectives)\n",
    "    - [📤 Inference: Autoregression and Decoding](#transformer-inference)\n",
    "- [🔍 Why This Matters for Our Use Cases](#why-this-matters)\n",
    "    - [💬 Chatbot → Decoder-only Transformers](#chatbot-transformers)\n",
    "    - [📝 Summarization → Encoder-Decoder Transformers](#summarization-transformers)\n",
    "    - [📊 Sentiment Analysis → Encoder-only Models](#sentiment-transformers)\n",
    "- [🔚 Closing Notes](#closing-notes)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5a8ce",
   "metadata": {},
   "source": [
    "<a id=\"why-transformers\"></a>\n",
    "# 🧠 Why Transformers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e5101",
   "metadata": {},
   "source": [
    "<a id=\"embeddings-and-tokens\"></a>\n",
    "# 🔡 Embeddings and Tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82138b6",
   "metadata": {},
   "source": [
    "<a id=\"tokenization-basics\"></a>\n",
    "#### 🧱 Tokenization Basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8d3d3",
   "metadata": {},
   "source": [
    "<a id=\"embedding-types\"></a>\n",
    "#### 🔢 Word, Subword, and Sentence Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a24680",
   "metadata": {},
   "source": [
    "<a id=\"positional-encoding\"></a>\n",
    "#### 📐 Positional Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a09f1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6196a1d",
   "metadata": {},
   "source": [
    "<a id=\"attention-mechanism\"></a>\n",
    "# 🌀 Attention Mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2e028",
   "metadata": {},
   "source": [
    "<a id=\"what-is-attention\"></a>\n",
    "#### 👀 What is Attention?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136ef9d",
   "metadata": {},
   "source": [
    "<a id=\"scaled-dot-product-attention\"></a>\n",
    "#### 📏 Scaled Dot-Product Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db73e57",
   "metadata": {},
   "source": [
    "<a id=\"multi-head-attention\"></a>\n",
    "#### 🎛️ Multi-Head Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ddfc9",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61bd73",
   "metadata": {},
   "source": [
    "<a id=\"transformer-building-blocks\"></a>\n",
    "# 🏗️ Transformer Building Blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4c9d9",
   "metadata": {},
   "source": [
    "<a id=\"transformer-components\"></a>\n",
    "#### 🧱 Layer Norm, Residuals, and Feedforward Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f8fca",
   "metadata": {},
   "source": [
    "<a id=\"encoder-vs-decoder\"></a>\n",
    "#### 🔁 Encoder vs Decoder Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4b1a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93e788a6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a3583",
   "metadata": {},
   "source": [
    "<a id=\"transformer-end-to-end\"></a>\n",
    "# 📦 End-to-End Transformer Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc36c7",
   "metadata": {},
   "source": [
    "<a id=\"training-objectives\"></a>\n",
    "#### 📈 Training Objective (Next Token, MLM, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059e141",
   "metadata": {},
   "source": [
    "<a id=\"transformer-inference\"></a>\n",
    "#### 📤 Inference: Autoregression and Decoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5e011",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a9d9f",
   "metadata": {},
   "source": [
    "<a id=\"why-this-matters\"></a>\n",
    "# 🔍 Why This Matters for Our Use Cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07aa8f8",
   "metadata": {},
   "source": [
    "<a id=\"chatbot-transformers\"></a>\n",
    "#### 💬 Chatbot → Decoder-only Transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b879d1",
   "metadata": {},
   "source": [
    "<a id=\"summarization-transformers\"></a>\n",
    "#### 📝 Summarization → Encoder-Decoder Transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d4982",
   "metadata": {},
   "source": [
    "<a id=\"sentiment-transformers\"></a>\n",
    "#### 📊 Sentiment Analysis → Encoder-only Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599c26a",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de78ba1",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# 🔚 Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe813feb",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
